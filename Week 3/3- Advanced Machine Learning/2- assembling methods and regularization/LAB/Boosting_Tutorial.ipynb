{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "Boosting algorithms are powerful techniques used to improve the performance of weak learners. In this tutorial, we will explore how to use AdaBoost, XGBoost, and Gradient Boosting to predict whether a client will subscribe to a term deposit based on the Bank Marketing dataset. This dataset contains information on direct marketing campaigns of a Portuguese banking institution."
      ],
      "metadata": {
        "id": "qbXhuePolXKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##AdaBoost Tutorial\n"
      ],
      "metadata": {
        "id": "_hTnB_ZUlo4l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 1: Import Required Libraries\n",
        "First, import the necessary libraries for data manipulation, model training, and evaluation."
      ],
      "metadata": {
        "id": "UbOTwlJ4lx40"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JfWrWb4Wk8hH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 2: Load and Preprocess the Dataset\n",
        "Load the Bank Marketing dataset and preprocess it. This includes handling missing values, encoding categorical variables, and splitting the data into features and target variables."
      ],
      "metadata": {
        "id": "IUZB4tAnmLxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip\"\n",
        "!wget $url # Download the zip file\n",
        "!unzip bank-additional.zip # Unzip the file\n",
        "data = pd.read_csv('bank-additional/bank-additional-full.csv', delimiter=';') # Load the data\n",
        "\n",
        "# Encode categorical variables\n",
        "data = pd.get_dummies(data, drop_first=True)\n",
        "\n",
        "# Split the data into features and target variable\n",
        "X = data.drop('y_yes', axis=1)\n",
        "y = data['y_yes']"
      ],
      "metadata": {
        "id": "WVRRXzZDmOBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 3: Split the Dataset\n",
        "Split the dataset into training and testing sets to evaluate the performance of the models."
      ],
      "metadata": {
        "id": "Lj1kXkthmcpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n"
      ],
      "metadata": {
        "id": "kKwDqYYrmeYQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 4: Initialize and Train the AdaBoost Classifier\n",
        "Initialize a Decision Tree classifier and use it as the base estimator for the AdaBoost classifier."
      ],
      "metadata": {
        "id": "QkGTqL6OmtXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize base classifier and AdaBoost Meta-estimator\n",
        "base_estimator = DecisionTreeClassifier(max_depth=1)\n",
        "adaboost_classifier = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=50, random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "adaboost_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = adaboost_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model's accuracy\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f'AdaBoost Classifier Model Accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "id": "V9SHMVeFmsfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##XGBoost Tutorial\n"
      ],
      "metadata": {
        "id": "cyHWV9HRm0T0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 1: Import Required Libraries\n",
        "First, import the necessary libraries for data manipulation, model training, and evaluation."
      ],
      "metadata": {
        "id": "UqhPu5jfm8GB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "yDt8m9G9m6xA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 2: Load and Preprocess the Dataset\n",
        "Load the Bank Marketing dataset and preprocess it. This includes handling missing values, encoding categorical variables, and splitting the data into features and target variables."
      ],
      "metadata": {
        "id": "0ax-nGSfntwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load the dataset\n",
        "# url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip\"\n",
        "# !wget $url # Download the zip file\n",
        "# !unzip bank-additional.zip # Unzip the file\n",
        "# data = pd.read_csv('bank-additional/bank-additional-full.csv', delimiter=';') # Load the data\n",
        "\n",
        "# Encode categorical variables\n",
        "data = pd.get_dummies(data, drop_first=True)\n",
        "\n",
        "# Split the data into features and target variable\n",
        "X = data.drop('y_yes', axis=1)\n",
        "y = data['y_yes']"
      ],
      "metadata": {
        "id": "VW1t1XCxnxhC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 3: Split the Dataset\n",
        "Split the dataset into training and testing sets to evaluate the performance of the models."
      ],
      "metadata": {
        "id": "NXX_PSXSoHmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "Cdh8eq8zoIxi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 4: Initialize and Train the XGBoost Classifier\n",
        "Initialize and train the XGBoost classifier."
      ],
      "metadata": {
        "id": "YjBKszY3oN42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train the XGBoost classifier\n",
        "xgb_classifier = XGBClassifier(n_estimators=50, random_state=42)\n",
        "xgb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = xgb_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model's accuracy\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f'XGBoost Classifier Model Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "zHkLiLENoRPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Gradient Boosting Tutorial\n"
      ],
      "metadata": {
        "id": "HC5D5c0hoUVc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 1: Import Required Libraries\n",
        "First, import the necessary libraries for data manipulation, model training, and evaluation."
      ],
      "metadata": {
        "id": "N8S9U-41oab4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "tJRkKxR9oYEK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 2: Load and Preprocess the Dataset\n",
        "Load the Bank Marketing dataset and preprocess it. This includes handling missing values, encoding categorical variables, and splitting the data into features and target variables."
      ],
      "metadata": {
        "id": "Jp5NR3ByoelM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load the dataset\n",
        "# url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip\"\n",
        "# !wget $url # Download the zip file\n",
        "# !unzip bank-additional.zip # Unzip the file\n",
        "# data = pd.read_csv('bank-additional/bank-additional-full.csv', delimiter=';') # Load the data\n",
        "\n",
        "# Encode categorical variables\n",
        "data = pd.get_dummies(data, drop_first=True)\n",
        "\n",
        "# Split the data into features and target variable\n",
        "X = data.drop('y_yes', axis=1)\n",
        "y = data['y_yes']"
      ],
      "metadata": {
        "id": "BPS8_qBrohcf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 3: Split the Dataset\n",
        "Split the dataset into training and testing sets to evaluate the performance of the models."
      ],
      "metadata": {
        "id": "hVjHzyr7opoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "IGe6bC74oq3q"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 4: Initialize and Train the Gradient Boosting Classifier\n",
        "Initialize and train the Gradient Boosting classifier."
      ],
      "metadata": {
        "id": "lFkcaygKoyCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train the Gradient Boosting classifier\n",
        "gradient_boosting_classifier = GradientBoostingClassifier(n_estimators=50, random_state=42)\n",
        "gradient_boosting_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = gradient_boosting_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model's accuracy\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f'Gradient Boosting Classifier Model Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "N4saJTWeoxwV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}